# -*- coding: utf-8 -*-
"""240322 Different ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xEicAgqj83nBw5-61IvbcUmI4UlTjz1j

#Recall the Data
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import random
from torch.utils.data import Dataset, DataLoader
import pandas as pd
!pip install pandas numpy scikit-learn tensorflow
import pandas as pd
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

print(torch.__version__)

from google.colab import drive
drive.mount('/content/drive')

finaldata = pd.read_csv("/content/drive/MyDrive/capstone_yb/Voting ML/DATA/cleaned_finaldata.csv")

X = finaldata.drop(columns=['Geography', 'Geographic Area Name','Biden_proportion','Estimate!!Households!!Median income (dollars)','Vote Count', 'Precinct','County',
                            'Estimate!!Families!!Median income (dollars)','Estimate!!Nonfamily households!!Median income (dollars)', 'Estimate!!Married-couple families!!Median income (dollars)'])
X = X.astype(float)
X.dtypes

y = finaldata['Biden_proportion']

import copy
import numpy as np
import tqdm
from sklearn.model_selection import train_test_split

# train-test split of the dataset / chaning split of data to Pytorch
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)
X_train = torch.tensor(X_train.values, dtype=torch.float32)
y_train = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)
X_test = torch.tensor(X_test.values, dtype=torch.float32)
y_test = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)

print(X_train.shape)
print(y_train.shape)

"""#LInear Regression"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np

# PyTorch Tensor를 numpy 배열로 변환
X_train_np = X_train.numpy()
y_train_np = y_train.numpy().reshape(-1)
X_test_np = X_test.numpy()
y_test_np = y_test.numpy().reshape(-1)

# LInear Regression
linear_model = LinearRegression()
linear_model.fit(X_train_np, y_train_np)

# Model Evaluation
y_pred = linear_model.predict(X_test_np)
mse = mean_squared_error(y_test_np, y_pred)
rmse = np.sqrt(mse)
print(f"Linear Regression RMSE: {rmse}")

"""# Polynomial Regression with Regularization"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import Ridge

# (Polynomial Regression) with Regularization
polynomial_degree = 2  # 다항식 차수
alpha = 1.0  # 정규화 강도
poly_model = make_pipeline(PolynomialFeatures(degree=polynomial_degree), Ridge(alpha=alpha))

# Model Fit
poly_model.fit(X_train_np, y_train_np)

# Model Evaluation
y_pred_poly = poly_model.predict(X_test_np)
mse_poly = mean_squared_error(y_test_np, y_pred_poly)
rmse_poly = np.sqrt(mse_poly)
print(f"Polynomial Regression (Ridge) RMSE: {rmse_poly}")

"""#Ensemble Model: RandomForestRegressor"""

from sklearn.ensemble import RandomForestRegressor

# Random Forest Regressor
random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)
random_forest_model.fit(X_train_np, y_train_np)

# Model Evaluation
y_pred_rf = random_forest_model.predict(X_test_np)
mse_rf = mean_squared_error(y_test_np, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)
print(f"Random Forest Regression RMSE: {rmse_rf}")

"""#Support Vector Regressor(SVR)"""

from sklearn.svm import SVR

# Support Vector Regressor(SVR)
svr_model = SVR(kernel='rbf')
svr_model.fit(X_train_np, y_train_np)

#Model Evaluation
y_pred_svr = svr_model.predict(X_test_np)
mse_svr = mean_squared_error(y_test_np, y_pred_svr)
rmse_svr = np.sqrt(mse_svr)
print(f"Support Vector Regression RMSE: {rmse_svr}")

"""##The best model: based on the information provided, the Random Forest model achieved the best performance with a Root Mean Square Error (RMSE) of approximately 0.08092192965975098, compared to the other models evaluated.

#Evaluation
"""

merged_df = pd.read_csv("/content/drive/MyDrive/processed_data.csv")
merged_df

class CountyDataset2(Dataset):
    def __init__(self, finaldata):
        f =  finaldata.drop(columns=['Geography', 'Geographic Area Name','Precinct','County', 'Vote Count','Estimate!!Households!!Median income (dollars)','average_Biden_proportion',
                            'Estimate!!Families!!Median income (dollars)','Estimate!!Nonfamily households!!Median income (dollars)', 'Estimate!!Married-couple families!!Median income (dollars)']).astype(float)
        self.X = f.values.tolist()
        self.y = finaldata['average_Biden_proportion'].tolist()
        self.county_info = finaldata['County'].tolist()

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32), self.county_info[idx]

# Define the CountyDataLoader class
class CountyDataLoader:
    def __init__(self, dataset, random_state=None):
        self.dataset = dataset
        self.counties = list(set(dataset.county_info))
        self.random_state = random_state

    def __iter__(self):
        for county in self.counties:
            county_indices = [i for i, c in enumerate(self.dataset.county_info) if c == county]
            batch_X = [self.dataset.X[i] for i in county_indices]
            batch_y = [self.dataset.y[i] for i in county_indices]
            yield batch_X, batch_y

dataset_evaluation = CountyDataset2(merged_df)
county_dataloader2 = CountyDataLoader(dataset_evaluation)

from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor()

model.fit(X_train, y_train)

from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
import numpy as np
import time

# RandomForestRegressor model trian
model = RandomForestRegressor()
model.fit(X_train_np, y_train_np.ravel())  # .ravel()을 사용하여 y_train을 1차원 배열로 변환

start_time = time.time()

# All test set
y_pred = model.predict(X_test_np)

# Model consume
end_time = time.time()

# RMSE calculation
mse = mean_squared_error(y_test_np, y_pred)
rmse = np.sqrt(mse)

# Result
print(f'Random Forest Regression RMSE: {rmse}')
print(f'Evaluation took {end_time - start_time} seconds')

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

# 모델 정의
model = RandomForestRegressor()

# cross_val_score
scores = cross_val_score(model, X_train_np, y_train_np, cv=5, scoring='neg_root_mean_squared_error')

# 교차검증으로부터의 RMSE 점수 출력 (neg_root_mean_squared_error는 음수 값으로 반환됨으로, 부호를 변경합니다)
print("RMSE scores:", -scores)
print("Average RMSE:", -scores.mean())

import matplotlib.pyplot as plt

# 예측 값과 실제 값의 분포 시각화
plt.scatter(y_test_np, y_pred, alpha=0.5)
plt.xlabel('Actual values')
plt.ylabel('Predicted values')
plt.title('Actual vs Predicted values')
plt.plot([min(y_test_np), max(y_test_np)], [min(y_test_np), max(y_test_np)], 'r')
plt.show()

"""The Random Forest Regression model demonstrated the best predictive performance compared to other models. With an RMSE value of 0.0797, it showed the lowest prediction error, indicating a smaller average difference between the predicted and actual values. Additionally, cross-validation confirmed the model's consistency and reliability.

These results suggest that the Random Forest model effectively learns from various feature variables and captures the complex relationships within the data, leading to accurate predictions of the Biden proportion. Therefore, it is reasonable to select the Random Forest Regression model as the optimal model for this project.
"""